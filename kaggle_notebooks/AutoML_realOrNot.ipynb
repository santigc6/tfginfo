{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import h2o\nfrom h2o.automl import H2OAutoML\nimport pandas as pd","execution_count":543,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h2o.init()","execution_count":544,"outputs":[{"output_type":"stream","text":"Checking whether there is an H2O instance running at http://localhost:54321 . connected.\nWarning: Your H2O cluster version is too old (3 months and 13 days)! Please download and install the latest version from http://h2o.ai/download/\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"--------------------------  ------------------------------------------------------------------\nH2O cluster uptime:         40 mins 29 secs\nH2O cluster timezone:       Etc/UTC\nH2O data parsing timezone:  UTC\nH2O cluster version:        3.26.0.10\nH2O cluster version age:    3 months and 13 days !!!\nH2O cluster name:           H2O_from_python_unknownUser_waku8u\nH2O cluster total nodes:    1\nH2O cluster free memory:    3.219 Gb\nH2O cluster total cores:    4\nH2O cluster allowed cores:  4\nH2O cluster status:         locked, healthy\nH2O connection url:         http://localhost:54321\nH2O connection proxy:       {'http': None, 'https': None}\nH2O internal security:      False\nH2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\nPython version:             3.6.6 final\n--------------------------  ------------------------------------------------------------------","text/html":"<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n<td>40 mins 29 secs</td></tr>\n<tr><td>H2O cluster timezone:</td>\n<td>Etc/UTC</td></tr>\n<tr><td>H2O data parsing timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O cluster version:</td>\n<td>3.26.0.10</td></tr>\n<tr><td>H2O cluster version age:</td>\n<td>3 months and 13 days !!!</td></tr>\n<tr><td>H2O cluster name:</td>\n<td>H2O_from_python_unknownUser_waku8u</td></tr>\n<tr><td>H2O cluster total nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O cluster free memory:</td>\n<td>3.219 Gb</td></tr>\n<tr><td>H2O cluster total cores:</td>\n<td>4</td></tr>\n<tr><td>H2O cluster allowed cores:</td>\n<td>4</td></tr>\n<tr><td>H2O cluster status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O connection url:</td>\n<td>http://localhost:54321</td></tr>\n<tr><td>H2O connection proxy:</td>\n<td>{'http': None, 'https': None}</td></tr>\n<tr><td>H2O internal security:</td>\n<td>False</td></tr>\n<tr><td>H2O API Extensions:</td>\n<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n<tr><td>Python version:</td>\n<td>3.6.6 final</td></tr></table></div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":441,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/nlp-getting-started/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ndata_to_predict = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsubmission = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","execution_count":586,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":443,"outputs":[{"output_type":"execute_result","execution_count":443,"data":{"text/plain":"   id keyword location  \\\n0   1     NaN      NaN   \n1   4     NaN      NaN   \n2   5     NaN      NaN   \n3   6     NaN      NaN   \n4   7     NaN      NaN   \n\n                                                                    text  \\\n0  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n1                                 Forest fire near La Ronge Sask. Canada   \n2  All residents asked to 'shelter in place' are being notified by of...   \n3      13,000 people receive #wildfires evacuation orders in California    \n4  Just got sent this photo from Ruby #Alaska as smoke from #wildfire...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are being notified by of...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation orders in California</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfire...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_to_predict.head(5)","execution_count":444,"outputs":[{"output_type":"execute_result","execution_count":444,"data":{"text/plain":"   id keyword location  \\\n0   0     NaN      NaN   \n1   2     NaN      NaN   \n2   3     NaN      NaN   \n3   9     NaN      NaN   \n4  11     NaN      NaN   \n\n                                                                    text  \n0                                     Just happened a terrible car crash  \n1       Heard about #earthquake is different cities, stay safe everyone.  \n2  there is a forest fire at spot pond, geese are fleeing across the ...  \n3                               Apocalypse lighting. #Spokane #wildfires  \n4                          Typhoon Soudelor kills 28 in China and Taiwan  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are fleeing across the ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(5)","execution_count":445,"outputs":[{"output_type":"execute_result","execution_count":445,"data":{"text/plain":"   id  target\n0   0       0\n1   2       0\n2   3       0\n3   9       0\n4  11       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[['text', 'target']]\n\ntrain.columns = ['tweet', 'class']","execution_count":587,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_to_predict = data_to_predict[['text']]\n\ndata_to_predict.columns = ['tweet']","execution_count":588,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nhashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\nmentions = re.compile(r\"^@\\S+|\\s@\\S+\")\nurls1 = r\"(?:\\@|https?\\://)\\S+\"\nurls2 = r\"(?:\\@|http?\\://)\\S+\"\nurls_pat = r'|'.join((urls1, urls2))\nurls = re.compile(urls_pat)\n\ndef process_text(text):\n  text = hashtags.sub(' hashtag', text)\n  text = mentions.sub(' entity', text)\n  return text.strip().lower()\n  \ndef match_expr(pattern, string):\n  return not pattern.search(string) == None\n\ndef get_data_wo_urls(dataset):\n    link_with_urls = dataset.tweet.apply(lambda x: match_expr(urls, x))\n    return dataset[[not e for e in link_with_urls]]","execution_count":448,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tweet = train.tweet.apply(process_text)\ntrain = get_data_wo_urls(train)\ntrain.head(4)","execution_count":589,"outputs":[{"output_type":"execute_result","execution_count":589,"data":{"text/plain":"                                                                   tweet  \\\n0      our deeds are the reason of this hashtag may allah forgive us all   \n1                                 forest fire near la ronge sask. canada   \n2  all residents asked to 'shelter in place' are being notified by of...   \n3          13,000 people receive hashtag evacuation orders in california   \n\n   class  \n0      1  \n1      1  \n2      1  \n3      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>our deeds are the reason of this hashtag may allah forgive us all</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>forest fire near la ronge sask. canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all residents asked to 'shelter in place' are being notified by of...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13,000 people receive hashtag evacuation orders in california</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['tweet']","execution_count":450,"outputs":[{"output_type":"execute_result","execution_count":450,"data":{"text/plain":"0           our deeds are the reason of this hashtag may allah forgive us all\n1                                      forest fire near la ronge sask. canada\n2       all residents asked to 'shelter in place' are being notified by of...\n3               13,000 people receive hashtag evacuation orders in california\n4       just got sent this photo from ruby hashtag as smoke from hashtag p...\n                                        ...                                  \n7594    a gas thing just exploded and i heard screams and now the whole st...\n7602        a siren just went off and it wasn't the forney tornado warning ??\n7605    on the flip side i'm at walmart and there is a bomb and everyone h...\n7609    entity entity the out of control wild fires in california even in ...\n7611    police investigating after an e-bike collided with a car in little...\nName: tweet, Length: 3607, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(stop_words = 'english')\n\nX_train = train['tweet']\ny_train = train['class']\nX_train = tfidf_vectorizer.fit_transform(X_train)\n\nX_test = data_to_predict['tweet']\nX_test = tfidf_vectorizer.transform(X_test)","execution_count":590,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.DataFrame(X_train.toarray(), columns=tfidf_vectorizer.get_feature_names())\ndf1['clase']=list(y_train)\n\ndf2 = pd.DataFrame(X_test.toarray(), columns=tfidf_vectorizer.get_feature_names())","execution_count":603,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":585,"outputs":[{"output_type":"execute_result","execution_count":585,"data":{"text/plain":"(3607, 8459)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val = train_test_split(df1, test_size=0.2)","execution_count":605,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = h2o.H2OFrame(X_train)\nval = h2o.H2OFrame(X_val)\ntest = h2o.H2OFrame(df2)","execution_count":606,"outputs":[{"output_type":"stream","text":"Parse progress: |█████████████████████████████████████████████████████████| 100%\nParse progress: |█████████████████████████████████████████████████████████| 100%\nParse progress: |█████████████████████████████████████████████████████████| 100%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dim","execution_count":607,"outputs":[{"output_type":"execute_result","execution_count":607,"data":{"text/plain":"[2885, 8460]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val.dim","execution_count":608,"outputs":[{"output_type":"execute_result","execution_count":608,"data":{"text/plain":"[722, 8460]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.dim","execution_count":609,"outputs":[{"output_type":"execute_result","execution_count":609,"data":{"text/plain":"[3263, 8459]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['clase']=train['clase'].asfactor()\nval['clase']=val['clase'].asfactor()","execution_count":611,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train.columns\ny = 'clase'\nx.remove(y)\n\naml = H2OAutoML(max_runtime_secs = 600)\naml.train(x = x, y = y, training_frame = train, leaderboard_frame = val)","execution_count":458,"outputs":[{"output_type":"stream","text":"AutoML progress: |██████████████████████████████████████ (failed)\n","name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"Job with key $03017f00000132d4ffffffff$_8c141f147938497d140cde791f14f9f failed with an exception: water.exceptions.H2OConcurrentModificationException: Rollups not possible, because Vec was deleted: $04ff06000000ffffffff$_9c48ac1070d0e07713c11dd2cbf144f3\nstacktrace: \nwater.exceptions.H2OConcurrentModificationException: Rollups not possible, because Vec was deleted: $04ff06000000ffffffff$_9c48ac1070d0e07713c11dd2cbf144f3\n\tat water.fvec.RollupStats.start(RollupStats.java:307)\n\tat water.fvec.Vec.startRollupStats(Vec.java:915)\n\tat water.fvec.Vec.startRollupStats(Vec.java:903)\n\tat water.fvec.Frame.bulkRollups(Frame.java:512)\n\tat water.fvec.Frame.means(Frame.java:531)\n\tat hex.Model.makeBigScoreTask(Model.java:1575)\n\tat hex.Model.predictScoreImpl(Model.java:1598)\n\tat hex.Model.score(Model.java:1454)\n\tat hex.Model.score(Model.java:1438)\n\tat hex.Model.score(Model.java:1394)\n\tat ai.h2o.automl.Leaderboard.addModels(Leaderboard.java:236)\n\tat ai.h2o.automl.Leaderboard.addModel(Leaderboard.java:311)\n\tat ai.h2o.automl.AutoML.addModel(AutoML.java:1388)\n\tat ai.h2o.automl.AutoML.pollAndUpdateProgress(AutoML.java:651)\n\tat ai.h2o.automl.AutoML.pollAndUpdateProgress(AutoML.java:576)\n\tat ai.h2o.automl.AutoML.defaultXGBoosts(AutoML.java:988)\n\tat ai.h2o.automl.AutoML.learn(AutoML.java:380)\n\tat ai.h2o.automl.AutoML.run(AutoML.java:347)\n\tat ai.h2o.automl.H2OJob$1.compute2(H2OJob.java:32)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1423)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-458-8572d0b0017d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OAutoML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_runtime_secs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaderboard_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h2o/automl/autoh2o.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, fold_column, weights_column, validation_frame, leaderboard_frame, blending_frame)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mpoll_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll_training_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbosity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoll_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mpoll_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, poll_updates)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0;32m---> 78\u001b[0;31m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job with key %s failed with an exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000132d4ffffffff$_8c141f147938497d140cde791f14f9f failed with an exception: water.exceptions.H2OConcurrentModificationException: Rollups not possible, because Vec was deleted: $04ff06000000ffffffff$_9c48ac1070d0e07713c11dd2cbf144f3\nstacktrace: \nwater.exceptions.H2OConcurrentModificationException: Rollups not possible, because Vec was deleted: $04ff06000000ffffffff$_9c48ac1070d0e07713c11dd2cbf144f3\n\tat water.fvec.RollupStats.start(RollupStats.java:307)\n\tat water.fvec.Vec.startRollupStats(Vec.java:915)\n\tat water.fvec.Vec.startRollupStats(Vec.java:903)\n\tat water.fvec.Frame.bulkRollups(Frame.java:512)\n\tat water.fvec.Frame.means(Frame.java:531)\n\tat hex.Model.makeBigScoreTask(Model.java:1575)\n\tat hex.Model.predictScoreImpl(Model.java:1598)\n\tat hex.Model.score(Model.java:1454)\n\tat hex.Model.score(Model.java:1438)\n\tat hex.Model.score(Model.java:1394)\n\tat ai.h2o.automl.Leaderboard.addModels(Leaderboard.java:236)\n\tat ai.h2o.automl.Leaderboard.addModel(Leaderboard.java:311)\n\tat ai.h2o.automl.AutoML.addModel(AutoML.java:1388)\n\tat ai.h2o.automl.AutoML.pollAndUpdateProgress(AutoML.java:651)\n\tat ai.h2o.automl.AutoML.pollAndUpdateProgress(AutoML.java:576)\n\tat ai.h2o.automl.AutoML.defaultXGBoosts(AutoML.java:988)\n\tat ai.h2o.automl.AutoML.learn(AutoML.java:380)\n\tat ai.h2o.automl.AutoML.run(AutoML.java:347)\n\tat ai.h2o.automl.H2OJob$1.compute2(H2OJob.java:32)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1423)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"aml.leaderboard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aml.leader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = aml.leader.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = preds['predict']\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_final = preds.as_data_frame()\npreds_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['target'] = preds_final['predict']\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}