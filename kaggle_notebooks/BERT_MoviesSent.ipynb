{"cells":[{"metadata":{},"cell_type":"markdown","source":"### First of all, delete all the files from 'output' directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import os, shutil\n# folder = '/kaggle/working'\n# for filename in os.listdir(folder):\n#     file_path = os.path.join(folder, filename)\n#     try:\n#         if os.path.isfile(file_path) or os.path.islink(file_path):\n#             os.unlink(file_path)\n#         elif os.path.isdir(file_path):\n#             shutil.rmtree(file_path)\n#     except Exception as e:\n#         print('Failed to delete %s. Reason: %s' % (file_path, e))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Install dependencies"},{"metadata":{"trusted":true,"_uuid":"dfe807fccd48e29c405155cca9c0e12e639b09b8"},"cell_type":"code","source":"# Install deps\n\n!pip  install -q tensor2tensor\n!pip  install -q  tensorflow matplotlib\n!pip install -q bert-tensorflow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%env JOBLIB_TEMP_FOLDER=/tmp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imports"},{"metadata":{"trusted":true,"_uuid":"a476f75f38c40891b0b13f50ebdc72a6952f5ec2"},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nimport random\nimport warnings\nwarnings.filterwarnings('ignore',category=FutureWarning)\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n\nfrom bert.tokenization import FullTokenizer\nfrom tqdm import tqdm_notebook\nfrom tensorflow.keras import backend as K\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(1)\nnp.random.seed(1)\n\ntf.random.set_random_seed(seed = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/movie-review-sentiment-analysis-kernels-only/train.tsv.zip', sep='\\t')\ndata_to_predict = pd.read_csv('/kaggle/input/movie-review-sentiment-analysis-kernels-only/test.tsv.zip', sep='\\t')\nsubmission = pd.read_csv('/kaggle/input/movie-review-sentiment-analysis-kernels-only/sampleSubmission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_to_predict.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[['Phrase', 'Sentiment']]\ndata_to_predict = data_to_predict[['Phrase']]\ntrain.columns = ['review', 'polarity']\ndata_to_predict.columns = ['review']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"186bbc50a9bc7a1b73abcf3e4f97f250eea64b9c"},"cell_type":"code","source":"import bert\nfrom bert import run_classifier\nfrom bert import optimization\nfrom bert import tokenization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edf8e592a57423137a1ee9429f5dd66afb2c46c7"},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nfrom datetime import datetime\n# This is a path to an uncased (all lowercase) version of BERT\nBERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n#https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip\ndef create_tokenizer_from_hub_module():\n  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n  with tf.Graph().as_default():\n    bert_module = hub.Module(BERT_MODEL_HUB)\n    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n    with tf.Session() as sess:\n      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n                                    tokenization_info[\"do_lower_case\"]])\n      \n  return bert.tokenization.FullTokenizer(\n      vocab_file=vocab_file, do_lower_case=do_lower_case)\n\ntokenizer = create_tokenizer_from_hub_module()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40e74f2acf5d1b0edf63e5fc2eb45d70870d84b9"},"cell_type":"code","source":"# Params for bert model and tokenization\nbert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\nmax_seq_length = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(train, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_COLUMN = 'review'\nLABEL_COLUMN = 'polarity'\n# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\nlabel_list = [0, 1, 2, 3, 4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the InputExample class from BERT's run_classifier code to create examples from the data\ntrain_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n                                                                   text_a = x[DATA_COLUMN], \n                                                                   text_b = None, \n                                                                   label = x[LABEL_COLUMN]), axis = 1)\n\ntest_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n                                                                   text_a = x[DATA_COLUMN], \n                                                                   text_b = None, \n                                                                   label = x[LABEL_COLUMN]), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We'll set sequences to be at most 256 tokens long.\nMAX_SEQ_LENGTH = 256\n# Convert our train and test features to InputFeatures that BERT understands.\ntrain_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\ntest_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n                 num_labels):\n  \"\"\"Creates a classification model.\"\"\"\n\n  bert_module = hub.Module(\n      BERT_MODEL_HUB,\n      trainable=True)\n  bert_inputs = dict(\n      input_ids=input_ids,\n      input_mask=input_mask,\n      segment_ids=segment_ids)\n  bert_outputs = bert_module(\n      inputs=bert_inputs,\n      signature=\"tokens\",\n      as_dict=True)\n\n  # Use \"pooled_output\" for classification tasks on an entire sentence.\n  # Use \"sequence_outputs\" for token-level output.\n  output_layer = bert_outputs[\"pooled_output\"]\n\n  hidden_size = output_layer.shape[-1].value\n\n  # Create our own layer to tune for politeness data.\n  output_weights = tf.get_variable(\n      \"output_weights\", [num_labels, hidden_size],\n      initializer=tf.truncated_normal_initializer(stddev=0.02))\n\n  output_bias = tf.get_variable(\n      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n\n  with tf.variable_scope(\"loss\"):\n\n    # Dropout helps prevent overfitting\n    output_layer = tf.nn.dropout(output_layer, rate=0.1)\n\n    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n    logits = tf.nn.bias_add(logits, output_bias)\n    log_probs = tf.nn.log_softmax(logits, axis=-1)\n\n    # Convert labels into one-hot encoding\n    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n\n    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n    # If we're predicting, we want predicted labels and the probabiltiies.\n    if is_predicting:\n      return (predicted_labels, log_probs)\n\n    # If we're train/eval, compute loss between predicted and actual label\n    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n    loss = tf.reduce_mean(per_example_loss)\n    return (loss, predicted_labels, log_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_fn_builder actually creates our model function\n# using the passed parameters for num_labels, learning_rate, etc.\ndef model_fn_builder(num_labels, learning_rate, num_train_steps,\n                     num_warmup_steps):\n  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n\n    input_ids = features[\"input_ids\"]\n    input_mask = features[\"input_mask\"]\n    segment_ids = features[\"segment_ids\"]\n    label_ids = features[\"label_ids\"]\n\n    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n    \n    # TRAIN and EVAL\n    if not is_predicting:\n\n      (loss, predicted_labels, log_probs) = create_model(\n        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n\n      train_op = bert.optimization.create_optimizer(\n          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n\n      # Calculate evaluation metrics. \n      def metric_fn(label_ids, predicted_labels):\n        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n        f1_score = tf.contrib.metrics.f1_score(\n            label_ids,\n            predicted_labels)\n        auc = tf.metrics.auc(\n            label_ids,\n            predicted_labels)\n        recall = tf.metrics.recall(\n            label_ids,\n            predicted_labels)\n        precision = tf.metrics.precision(\n            label_ids,\n            predicted_labels) \n        true_pos = tf.metrics.true_positives(\n            label_ids,\n            predicted_labels)\n        true_neg = tf.metrics.true_negatives(\n            label_ids,\n            predicted_labels)   \n        false_pos = tf.metrics.false_positives(\n            label_ids,\n            predicted_labels)  \n        false_neg = tf.metrics.false_negatives(\n            label_ids,\n            predicted_labels)\n        return {\n            \"eval_accuracy\": accuracy,\n            \"f1_score\": f1_score,\n            \"auc\": auc,\n            \"precision\": precision,\n            \"recall\": recall,\n            \"true_positives\": true_pos,\n            \"true_negatives\": true_neg,\n            \"false_positives\": false_pos,\n            \"false_negatives\": false_neg\n        }\n\n      eval_metrics = metric_fn(label_ids, predicted_labels)\n\n      if mode == tf.estimator.ModeKeys.TRAIN:\n        return tf.estimator.EstimatorSpec(mode=mode,\n          loss=loss,\n          train_op=train_op)\n      else:\n          return tf.estimator.EstimatorSpec(mode=mode,\n            loss=loss,\n            eval_metric_ops=eval_metrics)\n    else:\n      (predicted_labels, log_probs) = create_model(\n        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n\n      predictions = {\n          'probabilities': log_probs,\n          'labels': predicted_labels\n      }\n      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n  # Return the actual model function in the closure\n  return model_fn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute train and warmup steps from batch size\n# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\nBATCH_SIZE = 32\nLEARNING_RATE = 2e-5\nNUM_TRAIN_EPOCHS = 3.0\n# Warmup is a period of time where hte learning rate \n# is small and gradually increases--usually helps training.\nWARMUP_PROPORTION = 0.1\n# Model configs\nSAVE_CHECKPOINTS_STEPS = 500\nSAVE_SUMMARY_STEPS = 100\nOUTPUT_DIR = \"output/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute # train and warmup steps from batch size\nnum_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\nnum_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify outpit directory and number of checkpoint steps to save\nrun_config = tf.estimator.RunConfig(\n    model_dir=OUTPUT_DIR,\n    save_summary_steps=SAVE_SUMMARY_STEPS,\n    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fn = model_fn_builder(\n  num_labels=len(label_list),\n  learning_rate=LEARNING_RATE,\n  num_train_steps=num_train_steps,\n  num_warmup_steps=num_warmup_steps)\n\nestimator = tf.estimator.Estimator(\n  model_fn=model_fn,\n  config=run_config,\n  params={\"batch_size\": BATCH_SIZE})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create an input function for training. drop_remainder = True for using TPUs.\ntrain_input_fn = bert.run_classifier.input_fn_builder(\n    features=train_features,\n    seq_length=MAX_SEQ_LENGTH,\n    is_training=True,\n    drop_remainder=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Beginning Training!')\ncurrent_time = datetime.now()\nestimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\nprint(\"Training took time \", datetime.now() - current_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_input_fn = run_classifier.input_fn_builder(\n    features=test_features,\n    seq_length=MAX_SEQ_LENGTH,\n    is_training=False,\n    drop_remainder=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics = estimator.evaluate(input_fn=test_input_fn, steps=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.at[\"BERT\",\"Accuracy\"] = metrics['eval_accuracy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getPrediction(in_sentences):\n  labels = [0, 1, 2, 3, 4]\n  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n  predictions = estimator.predict(predict_input_fn)\n  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_sentences = list(data_to_predict['review'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"predictions = getPrediction(pred_sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_sent = [x[-1] for x in predictions]\nsubmission['Sentiment'] = predicted_sent\nsubmission.to_csv('submission_movies.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}